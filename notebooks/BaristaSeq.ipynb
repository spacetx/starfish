{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BaristaSeq\n",
    "\n",
    "BaristaSeq is an assay that sequences padlock-probe initiated rolling circle\n",
    "amplified spots using a one-hot codebook. The publication for this assay can be\n",
    "found [here](https://www.ncbi.nlm.nih.gov/pubmed/29190363)\n",
    "\n",
    "This example processes a single field of view extracted from a tissue slide that\n",
    "measures gene expression in mouse primary visual cortex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import starfish\n",
    "import starfish.data\n",
    "from starfish import FieldOfView\n",
    "from starfish.types import Axes, Levels\n",
    "from starfish.util.plot import (\n",
    "    imshow_plane, intensity_histogram, overlay_spot_calls\n",
    ")\n",
    "\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data\n",
    "---------\n",
    "Import starfish and extract a single field of view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = starfish.data.BaristaSeq(use_test_data=False)\n",
    "\n",
    "nissl = exp.fov().get_image('nuclei')\n",
    "img = exp.fov().get_image(FieldOfView.PRIMARY_IMAGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "starfish data are 5-dimensional, but to demonstrate what they look like in a\n",
    "non-interactive fashion, it's best to visualize the data in 2-d. There are\n",
    "better ways to look at these data using the `starfish.display`\n",
    "method, which allows the user to page through each axis of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this vignette, we'll pick one plane and track it through the processing\n",
    "# steps\n",
    "plane_selector = {Axes.CH: 0, Axes.ROUND: 0, Axes.ZPLANE: 8}\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(ncols=2)\n",
    "imshow_plane(img, sel=plane_selector, ax=ax1, title=\"primary image\")\n",
    "imshow_plane(nissl, sel=plane_selector, ax=ax2, title=\"nissl image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register the data\n",
    "-----------------\n",
    "The first step in BaristaSeq is to do some rough registration. For this data,\n",
    "the rough registration has been done for us by the authors, so it is omitted\n",
    "from this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project into 2D\n",
    "---------------\n",
    "BaristaSeq is typically processed in 2d. Starfish allows users to reduce data using arbitrary\n",
    "methods via `starfish.image.Filter.Reduce`.  Here we max project Z for both the nissl images and\n",
    "the primary images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from starfish.image import Filter\n",
    "from starfish.types import FunctionSource\n",
    "max_projector = Filter.Reduce((Axes.ZPLANE,), func=FunctionSource.np(\"max\"))\n",
    "z_projected_image = max_projector.run(img)\n",
    "z_projected_nissl = max_projector.run(nissl)\n",
    "\n",
    "# show the projected data\n",
    "f, (ax1, ax2) = plt.subplots(ncols=2)\n",
    "imshow_plane(z_projected_image, sel={Axes.CH: 0, Axes.ROUND: 0}, ax=ax1, title=\"primary image\")\n",
    "imshow_plane(z_projected_nissl, sel={Axes.CH: 0, Axes.ROUND: 0}, title=\"nissl image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct Channel Misalignment\n",
    "----------------------------\n",
    "There is a slight miss-alignment of the C channel in the microscope used to\n",
    "acquire the data. This has been corrected for this data, but here is how it\n",
    "could be transformed using python code for future datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage.feature import register_translation\n",
    "# from skimage.transform import warp\n",
    "# from skimage.transform import SimilarityTransform\n",
    "# from functools import partial\n",
    "\n",
    "# # Define the translation\n",
    "# transform = SimilarityTransform(translation=(1.9, -0.4))\n",
    "\n",
    "# # C is channel 0\n",
    "# channels = (0,)\n",
    "\n",
    "# # The channel should be transformed in all rounds\n",
    "# rounds = np.arange(img.num_rounds)\n",
    "\n",
    "# # apply the transformation in place\n",
    "# slice_indices = product(channels, rounds)\n",
    "# for ch, round_, in slice_indices:\n",
    "#     selector = {Axes.ROUND: round_, Axes.CH: ch, Axes.ZPLANE: 0}\n",
    "#     tile = z_projected_image.get_slice(selector)[0]\n",
    "#     transformed = warp(tile, transform)\n",
    "#     z_projected_image.set_slice(\n",
    "#         selector=selector,\n",
    "#         data=transformed.astype(np.float32),\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Registration Artefacts\n",
    "-----------------------------\n",
    "There are some minor registration errors along the pixels for which y < 100\n",
    "and x < 50. Those pixels are dropped from this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registration_corrected: starfish.ImageStack = z_projected_image.sel(\n",
    "    {Axes.Y: (100, -1), Axes.X: (50, -1)}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct for bleed-through from Illumina SBS reagents\n",
    "----------------------------------------------------\n",
    "The following matrix contains bleed correction factors for Illumina\n",
    "sequencing-by-synthesis reagents. Starfish provides a LinearUnmixing method\n",
    "that will unmix the fluorescence intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(\n",
    "    [[ 1.  , -0.05,  0.  ,  0.  ],\n",
    "     [-0.35,  1.  ,  0.  ,  0.  ],\n",
    "     [ 0.  , -0.02,  1.  , -0.84],\n",
    "     [ 0.  ,  0.  , -0.05,  1.  ]]\n",
    ")\n",
    "rows = pd.Index(np.arange(4), name='bleed_from')\n",
    "cols = pd.Index(np.arange(4), name='bleed_to')\n",
    "unmixing_coeff = pd.DataFrame(data, rows, cols)\n",
    "\n",
    "lum = starfish.image.Filter.LinearUnmixing(unmixing_coeff)\n",
    "bleed_corrected = lum.run(registration_corrected, in_place=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the matrix shows that (zero-based!) channel 2 bleeds particularly heavily into\n",
    "channel 3. To demonstrate the effect of unmixing, we'll plot channels 2 and 3\n",
    "of round 0 before and after unmixing.\n",
    "\n",
    "Channel 2 should look relative unchanged, as it only receives a bleed through\n",
    "of 5% of channel 3. However, Channel 3 should look dramatically sparser after\n",
    "spots from Channel 2 have been subtracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO ambrosejcarr fix this.\n",
    "ch2_r0 = {Axes.CH: 2, Axes.ROUND: 0, Axes.X: (500, 700), Axes.Y: (500, 700)}\n",
    "ch3_r0 = {Axes.CH: 3, Axes.ROUND: 0, Axes.X: (500, 700), Axes.Y: (500, 700)}\n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2)\n",
    "imshow_plane(\n",
    "    registration_corrected,\n",
    "    sel=ch2_r0, ax=ax1, title=\"Channel 2\\nBefore Unmixing\"\n",
    ")\n",
    "imshow_plane(\n",
    "    registration_corrected,\n",
    "    sel=ch3_r0, ax=ax2, title=\"Channel 3\\nBefore Unmixing\"\n",
    ")\n",
    "imshow_plane(\n",
    "    bleed_corrected,\n",
    "    sel=ch2_r0, ax=ax3, title=\"Channel 2\\nAfter Unmixing\"\n",
    ")\n",
    "imshow_plane(\n",
    "    bleed_corrected,\n",
    "    sel=ch3_r0, ax=ax4, title=\"Channel 3\\nAfter Unmixing\"\n",
    ")\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove image background\n",
    "-----------------------\n",
    "To remove image background, BaristaSeq uses a White Tophat filter, which\n",
    "measures the background with a rolling disk morphological element and\n",
    "subtracts it from the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import opening, dilation, disk\n",
    "from functools import partial\n",
    "\n",
    "# calculate the background\n",
    "opening = partial(opening, selem=disk(5))\n",
    "\n",
    "background = bleed_corrected.apply(\n",
    "    opening,\n",
    "    group_by={Axes.ROUND, Axes.CH, Axes.ZPLANE}, verbose=False, in_place=False\n",
    ")\n",
    "\n",
    "wth = starfish.image.Filter.WhiteTophat(masking_radius=5)\n",
    "background_corrected = wth.run(bleed_corrected, in_place=False)\n",
    "\n",
    "f, (ax1, ax2, ax3) = plt.subplots(ncols=3)\n",
    "selector = {Axes.CH: 0, Axes.ROUND: 0, Axes.X: (500, 700), Axes.Y: (500, 700)}\n",
    "imshow_plane(bleed_corrected, sel=selector, ax=ax1, title=\"template\\nimage\")\n",
    "imshow_plane(background, sel=selector, ax=ax2, title=\"background\")\n",
    "imshow_plane(\n",
    "    background_corrected, sel=selector, ax=ax3, title=\"background\\ncorrected\"\n",
    ")\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale images to equalize spot intensities across channels\n",
    "---------------------------------------------------------\n",
    "The number of peaks are not uniform across rounds and channels,\n",
    "which prevents histogram matching across channels. Instead, a percentile value\n",
    "is identified and set as the maximum across channels, and the dynamic range is\n",
    "extended to equalize the channel intensities. We first demonatrate what\n",
    "scaling by the max value does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbp = starfish.image.Filter.Clip(p_max=100, level_method=Levels.SCALE_BY_CHUNK)\n",
    "scaled = sbp.run(background_corrected, n_processes=1, in_place=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to visualize this is to calculate the intensity histograms\n",
    "before and after this scaling and plot their log-transformed values. This\n",
    "should see that the histograms are better aligned in terms of intensities.\n",
    "It gets most of what we want, but the histograms are still slightly shifted;\n",
    "a result of high-value outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scaling_result(\n",
    "    template: starfish.ImageStack, scaled: starfish.ImageStack\n",
    "):\n",
    "    f, (before, after) = plt.subplots(ncols=4, nrows=2)\n",
    "    for channel, ax in enumerate(before):\n",
    "        title = f'Before scaling\\nChannel {channel}'\n",
    "        intensity_histogram(\n",
    "            template, sel={Axes.CH: channel, Axes.ROUND: 0}, ax=ax, title=title,\n",
    "            log=True, bins=50,\n",
    "        )\n",
    "        ax.set_xlim(0, 0.007)\n",
    "    for channel, ax in enumerate(after):\n",
    "        title = f'After scaling\\nChannel {channel}'\n",
    "        intensity_histogram(\n",
    "            scaled, sel={Axes.CH: channel, Axes.ROUND: 0}, ax=ax, title=title,\n",
    "            log=True, bins=50,\n",
    "        )\n",
    "    f.tight_layout()\n",
    "    return f\n",
    "\n",
    "f = plot_scaling_result(background_corrected, scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat this scaling by the 99.8th percentile value, which does a better job\n",
    "of equalizing the intensity distributions.\n",
    "\n",
    "It should also be visible that exactly 0.2% of values take on the max value\n",
    "of 1. This is a result of setting any value above the 99.8th percentile to 1,\n",
    "and is a trade-off made to eliminate large-value outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbp = starfish.image.Filter.Clip(p_max=99.8, level_method=Levels.SCALE_BY_CHUNK)\n",
    "scaled = sbp.run(background_corrected, n_processes=1, in_place=False)\n",
    "\n",
    "f = plot_scaling_result(background_corrected, scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect Spots\n",
    "We use a pixel spot decoder to identify the gene target for each spot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psd = starfish.spots.DetectPixels.PixelSpotDecoder(\n",
    "    codebook=exp.codebook, metric='euclidean', distance_threshold=0.5,\n",
    "    magnitude_threshold=0.1, min_area=7, max_area=50\n",
    ")\n",
    "pixel_decoded, ccdr = psd.run(scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot a mask that shows where pixels have decoded to genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.imshow(np.squeeze(ccdr.decoded_image), cmap=plt.cm.nipy_spectral)\n",
    "ax.axis(\"off\")\n",
    "ax.set_title(\"Pixel Decoding Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the total counts for each gene from each spot detector.\n",
    "Do the below values make sense for this tissue and this probeset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_decoded_gene_counts = pd.Series(\n",
    "    *np.unique(pixel_decoded['target'], return_counts=True)[::-1]\n",
    ")\n",
    "\n",
    "print(pixel_decoded_gene_counts.sort_values(ascending=False)[:20])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "starfish-CI",
   "language": "python",
   "name": "starfish-ci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}